import os
import threading
import time
import webbrowser
import xxhash
import random
import multiprocessing as mp

import zerorpc
from kazoo.client import KazooClient
from kazoo.exceptions import NoNodeError
from kazoo.recipe.lock import LockTimeout
from zerorpc.exceptions import LostRemote
import logging

TARGET_CHUNKS = 10
MIN_CHUNK_SIZE = 1024000


class ZClient:
    def __init__(self, zoo_ip='localhost:2181', port=1400):
        logging.basicConfig(filename='log.txt')

        self.master = zerorpc.Client()
        self.zookeeper = KazooClient(hosts=zoo_ip)

        # connect to zookeeper for master ip, then connect to master
        master_ip = self._connect_to_zookeeper()
        self._connect_to_master(master_ip)

    def _connect_to_master(self, master_ip):
        try:
            print 'Connecting to master at %s' % master_ip
            self.master.connect(master_ip)
        except:
            print "Error connecting client to master"
            raise

    def _connect_to_zookeeper(self):
        try:
            self.zookeeper.start()
            master_ip = self.zookeeper.get('master')[0].split('@')[-1]
        except NoNodeError:
            print "No master record in zookeeper"
            raise  # TODO handle shadow master/waiting for master to reconnect later
        except:
            print "\n\tSome other error happened:"
            raise

        return master_ip

    def load(self, filename):
        with open(filename, 'rb') as f:
            data = f.read()

        self.write(filename, data)

    def close(self):
        """Closes connection with master"""
        self.master.close()

    def write(self, filename, data):
        """
        Creates a new file, writes the data
        :param filename:
        :param data:
        """

        if self._exists(filename):
            self.master.updatevrsn(filename, 1)
            self.edit(filename, data)
        else:
            seq = 0
            self.master.updatevrsn(filename, 0)

            start = time.time()

            try:
                lock = self.zookeeper.Lock('files/' + filename)
                lock.acquire(timeout=5)
                num_chunks, chunksize = self._num_chunks(len(data))
                # chunkuuids = self.master.alloc(filename, num_chunks, chunksize, seq)
                # self._write_chunks(chunkuuids, data, chunksize)
                chunkuuids = self.master.alloc2(filename, num_chunks, chunksize, seq)
                if not chunkuuids:
                    print "No chunkservers online"
                    return None
                chunklist = self._write_chunks(chunkuuids, data, chunksize)
                if chunklist:
                    self._update_master(filename, chunklist)
                else:
                    "Failed to write file"
                    return None
                end = time.time()
                print "Total time writing was %0.2f ms" % ((end - start) * 1000)
                print "Transfer rate: %0.f MB/s" % (len(data) / 1024 ** 2. / (end - start))

            except LockTimeout:
                return "File in use - try again later"
            finally:
                lock.release()

    def _update_master(self, filename, chunklist):

        print "File transfer successful. Updating master"
        try:
            self.master.update_file(filename, chunklist)
        except Exception as e:
            print "Error updating master: "

    def _exists(self, filename):

        response = None
        while response is None:
            try:
                response = self.master.exists(filename)
            except:
                pass

        return response

    def _num_chunks(self, size, chunksize=None):
        if not chunksize:
            chunksize = max(MIN_CHUNK_SIZE, size / TARGET_CHUNKS)
        return (size // chunksize) + (1 if size % chunksize > 0 else 0), chunksize

    def _write_chunks(self, chunkuuids, data, chunksize):
        chunks = [data[x:x + chunksize] for x in range(0, len(data), chunksize)]

        # connect with each chunkserver. TODO Change to check/establish later
        # chunkserver_nums = set(num for numlist in chunkuuids.values() for num in numlist)
        chunkserver_clients = self._establish_connection()
        # print "connection established"
        # raw_input('wait')
        # chunkuuids is already a table
        # write to each chunkserver

        finished = False
        call_replicate = False
        failed_chunkservers = []
        while not finished:
            chunklist = []  # list of successful writes for updating master
            for idx, (chunkuuid, c_locs) in enumerate(chunkuuids):
                chunklocs = [c_loc for c_loc in c_locs
                             if c_loc not in failed_chunkservers]
                if not chunklocs:
                    'No chunkservers to write to, write failed'
                    return False
                else:
                    try:
                        if len(chunklocs) > 1:
                            chunkloc, chunkloc2 = random.sample(chunklocs, 2)
                        else:
                            chunkloc = random.sample(chunklocs, 1)[0]
                            chunkloc2 = None

                        #print 'chunklocs = %s, chunkloc1 = %s, chunkloc2=%s' % (
                        #    chunklocs, chunkloc, chunkloc2)
                        digest = xxhash.xxh64(chunks[idx]).digest()
                        retdigest = chunkserver_clients[chunkloc].write(chunkuuid, chunks[idx],
                                                                        chunkloc2)
                        i = 3  # maximum amount of retries before we exit
                        while digest != retdigest:
                            if i == 0:
                                print "Failed transferring chunk without errors"
                                return False
                            retdigest = chunkserver_clients[chunkloc].write(chunkuuid, chunks[idx],
                                                                            chunkloc2)
                            i -= 1

                        if chunkloc2:
                            chunklist.append((chunkuuid, [chunkloc, chunkloc2]))
                        else:
                            chunklist.append((chunkuuid, [chunkloc]))

                        if idx == len(chunkuuids) - 1:
                            finished = True
                    except LostRemote:
                        failed_chunkservers.append(chunkloc)
                        finished = False
                        call_replicate = True
                        break
                    except Exception as e:
                        print 'Failed writing chunk %d to srv %s' % (idx, chunkloc)
                        print e.__doc__, e.message
                        #raise

        #print call_replicate, finished
        if call_replicate and finished:
            self.master.replicate()

        for client in chunkserver_clients.values():
            client.close()

        return chunklist

    # TODO only establish necessary target connections here
    def _establish_connection(self, targets=None):
        """
        Creates zerorpc client for each chunkserver
        :return:  Dictionary of zerorpc clients bound to chunkservers
        """
        chunkserver_clients = {}
        chunkservers = self.master.get('chunkservers')

        for chunkserver_num, chunkserver_ip in chunkservers.iteritems():
            zclient = zerorpc.Client()
            #print 'Client connecting to chunkserver %s at %s' % (chunkserver_num, chunkserver_ip)
            try:
                zclient.connect(chunkserver_ip)
                #zclient.print_name()
                chunkserver_clients[chunkserver_num] = zclient
            except LostRemote as e:
                self.master.print_exception('Lost remote in client', None)

        return chunkserver_clients

    def list(self):
        filelist = self.master.list()
        if filelist:
            for filename in filelist:
                print filename
        else:
            print 'No files in the system.'

    def read(self, filename):  # get metadata, then read chunks direct
        """
        Connects to each chunkserver and reads the chunks in order, then
        assembles the file by reducing
        :param filename:
        :return:  file contents
        """

        if not self._exists(filename):
            print "Read error - file does not exist"

        if filename == "#garbage_collection#":
            print self.master.get_chunkuuids(filename)
        else:
            try:
                start = time.time()

                # lock = self.zookeeper.Lock('files/' + filename)
                # lock.acquire(timeout=5)

                chunkuuids = self.master.get_chunkuuids(filename)
                # print "How many chunks? = %d" % len(chunkuuids)
                chunktable = self.master.get_file_chunks(filename)
                chunkserver_nums = set(num for numlist in chunktable.values() for num in numlist)
                # result = set(x for l in v for x in l)
                chunks = [None] * len(chunkuuids)
                chunkserver_clients = self._establish_connection(chunkserver_nums)
                jobs = []
                failed_chunkservers = []
                for i, chunkuuid in enumerate(chunkuuids):
                    chunkloc = chunktable[chunkuuid]
                    #print chunkloc
                    flag = False
                    id = 0

                    while flag is not True:
                        try:
                            chunklocs = [c_loc for c_loc in chunktable[chunkuuid] if c_loc not in failed_chunkservers]
                            lenchunkloc = len(chunklocs)
                            print 'chunklocs = ', chunklocs
                            if chunklocs:
                                next_chunkloc = random.sample(chunklocs, 1)[0]
                            else:
                                print 'Failed reading file - no chunkservers'
                                return None

                            print 'next chunkloc is ', next_chunkloc
                            thread = threading.Thread(
                                target=self._read(chunkuuid, chunkserver_clients[next_chunkloc],
                                                  chunks, i))
                            jobs.append(thread)
                            thread.start()
                            flag = True
                        except:
                            print 'Failed to connect to loc %d' % id
                            failed_chunkservers.append(next_chunkloc)
                            flag = False
                            id += 1
                            if id >= lenchunkloc:
                                print 'Failed reading file %s' % filename
                                return None

                data = ''.join(chunks)
                end = time.time()
                print "Total time reading was %0.2f ms" % ((end - start) * 1000)
                print "Transfer rate: %0.f MB/s" % (len(data) / 1024 ** 2. / (end - start))

            except LockTimeout:
                print "File in use - try again later"
                return None
            except Exception as e:
                print "Error reading file %s" % filename
                print e.__doc__
                print e.message
                return None
            finally:
                # lock.release()
                for client in chunkserver_clients.values():
                    client.close()
                pass

        return data

    def read_gui(self, filename):
        data = self.read(filename)

        fdir = "/tmp/gfs/files/"
        if not os.access(fdir, os.W_OK):
            os.makedirs(fdir)
        fn = os.path.abspath('/tmp/gfs/files/' + filename)
        f = open(fn, 'wb')
        f.write(data)
        f.flush()
        os.fsync(f.fileno())  # ensure data is on disk, f.close() does not ensure fsync itself
        f.close()
        webbrowser.open(fn)

    def read_mp(self, filename):
        """
        Connects to each chunkserver and reads the chunks in order, then
        assembles the file by reducing.  Returns details for editing
        :param filename:
        :param failed_chunkservers
        :return:  details, file contents
        """

        if not self._exists(filename):
            raise Exception("read error, file does not exist: " + filename)

        if filename == "#garbage_collection#":
            print self.master.get_chunkuuids(filename)
        else:
            try:
                lock = self.zookeeper.Lock('files/' + filename)
                lock.acquire(timeout=5)

                # chunks = []
                jobs = []
                chunkuuids = self.master.get_chunkuuids(filename)
                chunkdetails = []
                chunktable = self.master.get_file_chunks(filename)
                chunks = [None] * len(chunkuuids)
                chunkserver_clients = self._establish_connection()
                failed_chunkservers = []
                raw_input('Enter')
                for i, chunkuuid in enumerate(chunkuuids):
                    chunkloc = chunktable[chunkuuid]  # TODO FIX ME LATER, reads from [0] below

                    flag = False
                    id = 0
                    lenchunkloc = len(chunkloc)
                    pool = mp.Pool(processes=4)
                    while flag is not True and id <= lenchunkloc:
                        #print 'id=', id
                        try:

                            # thread = threading.Thread(
                            #     target=self._read(chunkuuid, chunkserver_clients[chunkloc[id]],
                            #                       chunks, i))
                            result = pool.apply_async(self._read, args=(chunkuuid,
                                                                        chunkserver_clients[
                                                                            chunkloc[id]], chunks,
                                                                        i))
                            jobs.append(result)
                            flag = True
                        except:
                            print 'Failed to connect to loc %d' % id
                            failed_chunkservers.append(chunkloc[id])
                            flag = False
                            id += 1
                            if id >= lenchunkloc:
                                print 'Error reading file %s' % filename
                                return None

                # block until all threads are done before reducing chunks
                for j in jobs:
                    j.wait()

                data = ''.join(chunks)

                # print chunkdetails

            except LockTimeout:
                print "File in use - try again later"
                return None
            except:
                print "Error reading file %s" % filename
                raise
            finally:
                lock.release()

            return data, chunkdetails, chunkserver_clients, failed_chunkservers

    def read_with_details(self, filename,failed_chunkservers):  # get metadata, then read chunks direct
        """
        Connects to each chunkserver and reads the chunks in order, then
        assembles the file by reducing.  Returns details for editing
        :param filename:
        :param failed_chunkservers
        :return:  details, file contents
        """

        if not self._exists(filename):
            raise Exception("read error, file does not exist: " + filename)

        if filename == "#garbage_collection#":
            print self.master.get_chunkuuids(filename)
        else:
            try:
                lock = self.zookeeper.Lock('files/' + filename)
                lock.acquire(timeout=5)

                # chunks = []
                jobs = []
                chunkuuids = self.master.get_chunkuuids(filename)
                chunkdetails = []
                chunktable = self.master.get_file_chunks(filename)
                chunks = [None] * len(chunkuuids)
                chunkserver_clients = self._establish_connection()
                #raw_input('Enter')
                for i, chunkuuid in enumerate(chunkuuids):
                    chunkloc = chunktable[chunkuuid]  # TODO FIX ME LATER, reads from [0] below
                    temp = {'chunkloc': chunkloc,
                            'chunkuid': chunkuuid}
                    chunkdetails.append(temp)

                    flag = False
                    id = 0
                    lenchunkloc = len(chunkloc)
                    while flag is not True and id <= lenchunkloc:
                        #print 'id=', id
                        try:
                            thread = threading.Thread(
                                target=self._read(chunkuuid, chunkserver_clients[chunkloc[id]],
                                                  chunks, i, temp))
                            jobs.append(thread)
                            thread.start()
                            flag = True
                        except:
                            print 'Failed to connect to loc %d' % id
                            failed_chunkservers.append(chunkloc[id])
                            flag = False
                            id += 1
                            if id >= lenchunkloc:
                                print 'Error reading file %s' % filename
                                return None

                # block until all threads are done before reducing chunks
                for j in jobs:
                    j.join()

                data = ''.join(chunks)

                # print chunkdetails

            except LockTimeout:
                print "File in use - try again later"
                return None
            except:
                print "Error reading file %s" % filename
                raise
            finally:
                lock.release()
                for client in chunkserver_clients.values():
                    client.close()

            return data, chunkdetails, chunkserver_clients, failed_chunkservers

    @staticmethod
    def _read(chunkuuid, chunkserver_client, chunks, i, temp=None):
        """
        Gets appropriate chunkserver to contact from master, and retrieves the chunk with
        chunkuuid. This function is passed to a threading service. Thread safe since each thread
        accesses only one index.
        :param chunkuuid:
        :param chunkserver_client: chunkserver to retrieve chunk from
        :param chunks: list of chunks we will append this chunk to
        :param i: current index we are working on
        :return: Calling threads in this fashion cannot return values, so we pass in chunks
        """
        # add md5 check

        chunk = chunkserver_client.read(chunkuuid)
        chunks[i] = chunk
        # update temp with chunk for edit details function if exists
        if temp:
            temp['chunk'] = chunk
            # print "Finished reading chunk %s " % chunkuuid

    def dump_metadata(self):
        self.master.dump_metadata()

    # TODO change for variable chunksize
    # def append(self, filename, data):
    #     if not self._exists(filename):
    #         raise Exception("append error, file does not exist: " + filename)
    #     num_chunks = self._num_chunks(len(data))
    #     append_chunkuuids = self.master.alloc_append(filename, num_chunks)
    #     self._write_chunks(append_chunkuuids, data, 1024)  # change 1024

    ####################################################################################

    def append(self, filename, data):
        try:
            lock = self.zookeeper.Lock('files/' + filename)
            lock.acquire(timeout=5)
            self._edit_append(filename, data)
        except LockTimeout:
            print "File in use - try again later"
            return None
        except:
            print "Error reading file %s" % filename
            raise
        finally:
            lock.release()

    def _edit_append(self, filename, data):
        """ Separate function, called if you already have a lock acquired for appending"""
        if not self._exists(filename):
            print "Can't append, file '%s' does not exist" % filename
            return False
        else:
            chunksize = self.master.get_chunksize(filename)
            last_chunk_id = self.master.get_last_chunkuuid(filename)
            num_chunks, _ = self._num_chunks(len(data), chunksize)
            seq = int(last_chunk_id.split('$%#')[1]) + 1
            append_chunkuuids = self.master.alloc2_chunks(num_chunks, filename, seq)
            # print "append_chuids", append_chunkuuids
            if not append_chunkuuids:
                print "No chunkservers online"
                return False
            chunklist = self._write_chunks(append_chunkuuids, data, chunksize)
            # print "chunklist = %s" % chunklist
            if chunklist:
                self._update_master(filename, chunklist)
                return True
            else:
                "Failed to write file"
                return False

    def deletechunk(self, filename, chunkdetails, len_newdata, len_olddata, chunksize):
        x = y = 0
        chunkids = []
        for chunkuuid in chunkdetails:
            if x > len_newdata:
                chunkids.append(chunkuuid['chunkuid'])
            x += chunksize
        self.master.delete_chunks(filename, chunkids)
        return True

    def replacechunk(self, chunkserver_clients, failed_chunkservers, chunkdetails, data1, data2, chunksize):
        x = y = 0
        # chunkserver_clients = self._establish_connection()  # can be avoided, pass from the edit function
        for x in range(0, len(data1), chunksize):
            if data1[x:x + chunksize] != data2[x:x + chunksize] or len(
                    data2[x:x + chunksize]) < chunksize:
                #print "replace '" + data1[x:x + chunksize] + "' with '" + data2[
                #                                                         x:x + chunksize] + "'"
                validservers = list(set(chunkdetails[y]['chunkloc']) - set(failed_chunkservers))
                for i in validservers:
                    try:
                        chunkserver_clients[i].write(chunkdetails[y]['chunkuid'],
                                                     data2[x:x + chunksize])
                    except:
                        pass

            y += 1
        return True

    # def append(self, filename, data):
    #     if not self._exists(filename):
    #         raise Exception("append error, file does not exist: " + filename)
    #     else:
    #         num_chunks = self._num_chunks(len(data))
    #         chunkuuids = self.master.get_chunkuuids(filename)[-1]
    #         seq = int(chunkuuids.split('$%#')[1]) + 1
    #         append_chunkuuids = self.master.alloc_append(num_chunks, filename, seq)
    #         self._write_chunks(append_chunkuuids, data)

    def delete(self, filename):
        if not self._exists(filename):
            raise Exception("append error, file does not exist: " + filename)
        else:
            self.master.delete(filename, "")

    def edit(self, filename, newdata):
        """
        Read the file with the read() from above and update only the
        chunkservers where the data in the chunk has changed
        """

        if not self._exists(filename):
            raise Exception("read error, file does not exist: " + filename)

        # TODO possibly change, read acquires full lock so this can't happen after asking lock below
        # kazoo lock is not reentrant, so it will block forever if the same thread acquires twice
        olddata, chunkdetails, chunkservers, failed_chunkservers = self.read_with_details(filename, [])

        if not olddata:
            return False  # exit if unable to read details

        try:
            lock = self.zookeeper.Lock('files/' + filename)
            lock.acquire(timeout=5)
            chunks = []
            i = 0
            chunkuuids = self.master.get_chunkuuids(filename)
            # chunkserver_clients = self._establish_connection()
            #
            # for chunkuuid in chunkuuids:
            #   temp={}
            # maybe use subprocess to execute the download process in parallel
            # may throw error if chunkserver dies off in between
            #   chunkloc = self.master.get_chunkloc(chunkuuid)
            #   chunk = chunkserver_clients[chunkloc[0]].read(chunkuuid)
            #   temp['chunkloc']=chunkloc
            #   temp['chunkuid']=chunkuuid
            #   temp['chunk']=chunk
            #   chunkdetails.append(temp)
            #   chunks.append(chunk)

            # olddata = reduce(lambda x, y: x + y, chunks)  # reassemble in order

            # print "\nCurrent data in " + filename + "\n" + olddata + "\nEdited data:\n" + newdata

            # newchunks = []
            # chunksize = self.master.get('chunksize')
            chunksize = self.master.get_chunksize(filename)
            len_newdata = len(newdata)
            len_olddata = len(olddata)
            # newchunks = [newdata[x:x + chunksize] for x in range(0, len_newdata, chunksize)]

            if len_newdata == len_olddata:
                if newdata == olddata:
                    print "no change in contents"
                else:
                    print "same size but content changed"
                    x = self.replacechunk(chunkservers, failed_chunkservers, chunkdetails, olddata, newdata, chunksize)
            elif len_newdata < len_olddata:
                print "deleted some contents"
                x = self.replacechunk(chunkservers, failed_chunkservers, chunkdetails,
                                      olddata[0:len_newdata], newdata, chunksize)
                #print "call fn() to delete chunks " + olddata[
                                                     # len_newdata + 1:] + " from chunk server"
                x = self.deletechunk(filename, chunkdetails, len_newdata, len_olddata, chunksize)
            elif len_newdata > len_olddata:
                print "added some contents"
                x = self.replacechunk(chunkservers, failed_chunkservers, chunkdetails, olddata,
                                      newdata[0:len_olddata], chunksize)
                #print "call fn() to add chunks '" + newdata[len_olddata + 1:] + "' to chunk server"
                x2 = self._edit_append(filename, newdata[len_olddata:])

            self.master.updatevrsn(filename, 1)

            try:
                for chunkserver in chunkservers:
                    chunkserver.close()
            except:
                pass

        except LockTimeout:
            print "File in use - try again later"
            return None
        except Exception as e:
            print "Error editing file %s - try again later" % filename
            print type(e).__name__, e.args
        finally:
            lock.release()

    def rename(self, filename, newfilename):
        if self._exists(filename):
            if not self._exists(newfilename):
                chunkuids = self.master.get_chunkuuids(filename)
                result = {}
                for chunkuid in chunkuids:
                    # maybe use subprocess to execute the download process in parallel
                    # may throw error if chunkserver dies off in between
                    chunklocs = self.master.get_chunkloc(chunkuid)
                    for chunkloc in chunklocs:
                        try:
                            result[chunkloc].append(chunkuid)
                        except:
                            result[chunkloc] = []
                            result[chunkloc].append(chunkuid)

                    self.master.rename(result, filename, newfilename)

            else:
                print "read error, file already exist: " + newfilename
        else:
            print "read error, file does not exist: " + filename
